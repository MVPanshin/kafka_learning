services:
 hadoop-namenode:
   image: apache/hadoop:3.4.1
   container_name: hadoop-namenode
   hostname: hadoop-namenode
   user: "root"
   restart: always
   platform: linux/amd64
   deploy:
     resources:
       limits:
         cpus: "1.0"   # Ограничение использования CPU
         memory: "2g"  # Ограничение использования RAM
   shm_size: 10G
   ports:
     - "9870:9870"  # HTTP-порт для Web UI HDFS NameNode
     - "9000:9000"  # RPC порт для запросов к NameNode
   networks:
     - confluent
   volumes:
     - ./config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
     - ./config/hdfs-site-namenode.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
     - ./namenode_entrypoint.sh:/namenode_entrypoint.sh
   entrypoint: ["/bin/bash", "/namenode_entrypoint.sh"]
   command: ["hdfs", "namenode"]


 hadoop-datanode-1:
   image: apache/hadoop:3.4.1
   container_name: hadoop-datanode-1
   hostname: hadoop-datanode-1
   user: "root"
   restart: always
   platform: linux/amd64
   deploy:
     resources:
       limits:
         cpus: "1.0"   # Ограничение использования CPU
         memory: "2g"  # Ограничение использования RAM
   shm_size: 10G
   depends_on:
     - hadoop-namenode
   ports:
     - "9864:9864"  # HTTP-порт для Web UI DataNode №1
     - "9970:9970"  # RPC порт для запросов от NameNode
   networks:
     - confluent  
   volumes:
     - ./config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
     - ./config/hdfs-site-datanode-1.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
     - ./datanode_entrypoint.sh:/datanode_entrypoint.sh
   entrypoint: ["/bin/bash", "/datanode_entrypoint.sh"]
   command: ["hdfs", "datanode"]


 hadoop-datanode-2:
   image: apache/hadoop:3.4.1
   container_name: hadoop-datanode-2
   hostname: hadoop-datanode-2
   user: "root"
   restart: always
   platform: linux/amd64
   deploy:
     resources:
       limits:
         cpus: "1.0"   # Ограничение использования CPU
         memory: "2g"  # Ограничение использования RAM
   shm_size: 10G
   depends_on:
     - hadoop-namenode
   ports:
     - "9865:9865"  # HTTP-порт для Web UI DataNode №2
     - "9971:9971"  # RPC порт для запросов от NameNode
   networks:
     - confluent
   volumes:
     - ./config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
     - ./config/hdfs-site-datanode-2.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
     - ./datanode_entrypoint.sh:/datanode_entrypoint.sh
   entrypoint: ["/bin/bash", "/datanode_entrypoint.sh"]
   command: ["hdfs", "datanode"]


 hadoop-datanode-3:
   image: apache/hadoop:3.4.1
   container_name: hadoop-datanode-3
   hostname: hadoop-datanode-3
   user: "root"
   restart: always
   platform: linux/amd64
   deploy:
     resources:
       limits:
         cpus: "1.0"   # Ограничение использования CPU
         memory: "2g"  # Ограничение использования RAM
   shm_size: 10G
   depends_on:
     - hadoop-namenode
   ports:
     - "9866:9866"  # HTTP-порт для Web UI DataNode №3
     - "9972:9972"  # RPC порт для запросов от NameNode
   networks:
     - confluent
   volumes:
     - ./config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
     - ./config/hdfs-site-datanode-3.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
     - ./datanode_entrypoint.sh:/datanode_entrypoint.sh
   entrypoint: ["/bin/bash", "/datanode_entrypoint.sh"]
   command: ["hdfs", "datanode"]

 spark-master:
   image: bitnami/spark:3.5.4
   container_name: spark-master
   networks:
     - confluent
   ports:
     - "7077:7077"  # Порт для подключения Executors
     - "8088:8088"  # HTTP-порт для Web UI Apache Spark master
   environment:
     SPARK_MODE: master
   volumes:
     - ./config/core-site.xml:/opt/spark/conf/core-site.xml
     - ./config/hdfs-site.xml:/opt/spark/conf/hdfs-site.xml

 spark-worker:
   image: bitnami/spark:3.5.4
   container_name: spark-worker
   networks:
     - confluent
   depends_on:
     - spark-master
   ports:
     - "8089:8089"  # HTTP-порт для Web UI Apache Spark worker
   environment:
     SPARK_MODE: worker
     SPARK_MASTER_URL: spark://spark-master:7077
   volumes:
     - ./config/core-site.xml:/opt/spark/conf/core-site.xml
     - ./config/hdfs-site.xml:/opt/spark/conf/hdfs-site.xml     

 spark-client:
   image: bitnami/spark:3.5.4
   container_name: spark-client
   networks:
     - confluent
   working_dir: /app
   volumes:
     - ./app/spark-hadoop:/app
     - ./drivers/postgresql-42.6.2.jar:/app/drivers/postgresql-42.6.2.jar
     - ./config/core-site.xml:/opt/spark/conf/core-site.xml
     - ./config/hdfs-site.xml:/opt/spark/conf/hdfs-site.xml     
   depends_on:
     - spark-master
     - spark-worker
   entrypoint: ["sleep", "infinity"]
   environment:
     KAFKA_BOOTSTRAP_SERVERS: kafka-destination-1:9192
     SCHEMA_REGISTRY_URL: http://schema-registry:8081
     HDFS_URI: http://hadoop-namenode:9870

networks:
 confluent:
  driver: bridge